# 支持向量机

由于团队对支持向量机的理解还不够深刻，因此下面请小高同志解释一下什么是支持向量机。

大家好，我是小高，下面我给大家讲一下什么是支持向量机。首先我们看一下线性可分和线性不可分的概念。

## 线性可分和线性不可分

假设有两类点，它们的特征空间如下：

![1](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/1.png)

显然我们可以很轻松得找到一条直线将它们分开：

![2](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/2.png)

因此这个数据集就称为线性可分的。

假设有另外两类点，它们的特征空间如下：

![3](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/3.png)

显然我们很难找一条直线将它们分开，所以这时必须要找一条曲线将它们分开：

![4](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/4.png)

因此这个数据集就称为线性不可分。

## 支持向量机

支持向量机是机器学习中最受欢迎的分类器了。为什么？因为支持向量机可以通过调整核函数来分类各种各样数据集：对于线性可分的，可以选择线性函数作为核函数；对于线性不可分的，可以选择径向基函数作为核函数。但也正因为核函数的技巧，使得支持向量机如此艰深难懂。下面我就直观得讲一下支持向量机的工作原理。

对于线性可分的特征空间：

![5](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/1.png)

我们要找到最优的直线将它们分开，既选择线性函数作为核函数即可：

![6](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/2.png)

对于线性不可分的特征空间：

![7](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/3.png)

先将它映射到高维空间，再用超平面分类：

![8](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/5.png)

最后将分类边界投射到低维，这样就得到了一条曲线：

![9](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/4.png)

其中选择不同的基函数，得到的高维空间中的像是不同的。

## 边界的比较

下面我们以鸢尾花数据集为例，比较一下决策树，Logistic回归，以线性函数作为核函数的支持向量机和以径向基函数作为核函数的支持向量机的分类边界。

```python
# -*- coding: utf-8 -*-
import numpy as np
import matplotlib.pyplot as plt
from sklearn import tree, linear_model, svm, datasets

# 提取训练集，其中特征个数为2，目标变量种类为2
iris = datasets.load_iris()
X = iris.data[:100, :2]
y = iris.target[:100]

# 构造预测集 
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, .02), np.arange(y_min, y_max, .02))

# 分类器们
clfs = [
    ('Decision Tree', tree.DecisionTreeClassifier()),
    ('Logistic Regression', linear_model.LogisticRegression()),
    ('SVM with linear kernel', svm.SVC(kernel='linear')),
    ('SVM with rbf kernel', svm.SVC(kernel='rbf'))
]

# 绘图
for i in range(len(clfs)):
    clf = clfs[i][1]
    clf.fit(X, y)
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    plt.subplot(2, 2, i + 1)
    plt.subplots_adjust(wspace=0.4, hspace=0.4)
    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm)
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())
    plt.title(clfs[i][0])

plt.show()
```

![10](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5/image/6.png)

- 决策树：边界不是直线，适用于线性不可分的情形，但由直线构成，不光滑
- Logistic回归：边界是直线，只适用于线性可分的情形
- 以线性函数作为核函数的支持向量机：边界是直线，只适用于线性可分的情形
- 以径向基函数作为核函数的支持向量机：边界是光滑曲线，适用于线性不可分的情形

## 习题集