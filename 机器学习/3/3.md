# 决策树

我们团队的小红还没男朋友，她妈妈正在给她张罗相亲的事，那我们来看看他们的对话：

- 小红：多大年纪了？
- 妈妈：26。
- 小红：长得帅不帅？
- 妈妈：挺帅的。
- 小红：收入高不？
- 妈妈：不算高，中等情况。
- 小红：是公务员不？
- 妈妈：是，在税务局上班呢。
- 小红：那好，我去见见。

小红的决策方式就是典型的决策树模式：

![1](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3/image/1.png)

那么下面我们就来看看如何使用决策树来分类的吧。

## 决策树

看一个关于海洋生物数据的表格：

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |是        |是      |
|是                    |是        |是      |
|是                    |否        |否      |
|否                    |是        |否      |
|否                    |是        |否      |

表格有两个特征：不浮出水面是否可以生存和是否有脚蹼，以及含有2个分类的目标变量。

分析完表格，我们来看看目标：通过两个特征作为划分的依据，来构建决策树，以此进行预测。那么问题来了，我们应该先选择哪一个特征作为划分的依据呢？这就涉及到熵和信息增益的概念了。

### 熵和信息增益

首先计算总样本的熵（其中的对数以2为底）：

> H(样本) = -p(属于鱼类)log(p(属于鱼类))-p(不属于鱼类)log(p(不属于鱼类)) = -0.4\*log(0.4)-0.6\*log(0.6) = 0.97

其次计算总样本在各个特征下的熵：

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |是        |是      |
|是                    |是        |是      |
|是                    |否        |否      |

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|否                    |是        |否      |
|否                    |是        |否      |

> H(样本|特征1) = p(特征1=不浮出水面可以生存)H(样本|特征1=不浮出水面可以生存) + p(特征1=不浮出水面不可以生存)H(样本|特征1=不浮出水面不可以生存) = 0.6\*0.92 + 0.4\*0 = 0.552

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |是        |是      |
|是                    |是        |是      |
|否                    |是        |否      |
|否                    |是        |否      |

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |否        |否      |

> H(样本|特征2) = p(特征2=有脚蹼)H(样本|特征2=有脚蹼) + p(特征2=没有脚蹼)H(样本|特征2=没有脚蹼) = 0.8\*1 + 0.2\*0 = 0.8

最后计算各个特征的信息增益：

> G(特征1) = H(样本) - H(样本|特征1) = 0.97 - 0.552 = 0.418

> G(特征2) = H(样本) - H(样本|特征2) = 0.97 - 0.8 = 0.17

由于特征1的信息增益大于特征2的信息增益，所以我们先以特征1划分，再以特征2划分。

### 构建决策树

先根据特征1划分，得到下面两个表格：

|是否有脚蹼|属于鱼类|
|----------|--------|
|是        |是      |
|是        |是      |
|否        |否      |

|是否有脚蹼|属于鱼类|
|----------|--------|
|是        |否      |
|是        |否      |

> 对于表格1，由于海洋生物可能是鱼类可能不是鱼类，因此还需要进一步划分；对于表格二，由于海洋生物均不为鱼类，因此分类完毕。如图：

![2](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3/image/2.png)

再根据特征2划分表格1，得到下面两个表格：

|属于鱼类|
|--------|
|是      |
|是      |

|属于鱼类|
|--------|
|否      |

> 类似上述分析，分类完毕。如图：

![3](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3/image/3.png)

> 这样一个决策树就构建完毕了！当一个海洋生物不浮出水面不可以生存而且没有脚蹼，那么它是不是鱼类呢？通过决策树，我们可以看出这样的海洋生物不是鱼类。

## 人民的好朋友scikit-learn

```python
# -*- coding: utf-8 -*-
from sklearn import tree

# 步骤一：明确分类器
clf = tree.DecisionTreeClassifier()

# 步骤二：训练，即构建决策树
train_data_X = [[1, 1], [1, 1], [1, 0], [0, 1], [0, 1]]
train_data_Y = [1, 1, 0, 0, 0]
clf.fit(train_data_X, train_data_Y)

# 步骤三：训练，不好意思，不小心把样本用光了，就跳过这一步骤了
# 步骤四：预测
print clf.predict([[0, 0]])[0] # 结果为0，因此预测结果不是鱼类
```

## 习题集

### 熵

假设一个数据集的目标变量有m个分类，那么该数据集的熵为

> H(样本) = \sum

写出熵的计算函数entropy，参数为数据集，返回值为对应的熵。

```python
def entropy(X, Y):
	'''calculate the entropy of table'''
```

### 鸢尾花数据集与决策树