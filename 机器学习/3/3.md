# 决策树

我们团队的小红还没男朋友，她妈妈正在给她张罗相亲的事，那我们来看看他们的对话：

- 小红：多大年纪了？
- 妈妈：26。
- 小红：长得帅不帅？
- 妈妈：挺帅的。
- 小红：收入高不？
- 妈妈：不算高，中等情况。
- 小红：是公务员不？
- 妈妈：是，在税务局上班呢。
- 小红：那好，我去见见。

小红的决策方式就是典型的决策树模式：

![1](https://github.com/im-iron-man/data-analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3/image/1.png)

那么下面我们就来看看如何使用决策树来分类的吧。

## 决策树

看一个关于海洋生物数据的表格：

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |是        |是      |
|是                    |是        |是      |
|是                    |否        |否      |
|否                    |是        |否      |
|否                    |是        |否      |

这个表格共有两个特征：不浮出水面是否可以生存和是否有脚蹼，以及含有2个分类的目标变量。

分析完了表格，我们来看看目标：通过两个特征作为划分的依据，来构建决策树，以此进行预测。那么问题来了，我们应该先选择哪一个特征作为划分的依据呢？这就涉及到熵和信息增益的概念了。

## 熵和信息增益

首先计算总样本的熵：

> H(样本) = -p(属于鱼类)log(p(属于鱼类))-p(不属于鱼类)log(p(不属于鱼类)) = -0.4\*log(0.4)-0.6\*log(0.6) = 0.97

其次计算总样本在各个特征下的熵：

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |是        |是      |
|是                    |是        |是      |
|是                    |否        |否      |

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|否                    |是        |否      |
|否                    |是        |否      |

> H(样本|特征1) = p(特征1=不浮出水面可以生存)H(样本|特征1=不浮出水面可以生存) + p(特征1=不浮出水面不可以生存)H(样本|特征1=不浮出水面不可以生存) = 0.6\*0.92 + 0.4\*0 = 0.552

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |是        |是      |
|是                    |是        |是      |
|否                    |是        |否      |
|否                    |是        |否      |

|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|
|----------------------|----------|--------|
|是                    |否        |否      |

> H(样本|特征2) = p(特征2=有脚蹼)H(样本|特征2=有脚蹼) + p(特征2=没有脚蹼)H(样本|特征2=没有脚蹼) = 0.8\*1 + 0.2\*0 = 0.8

最后计算各个特征的信息增益：

> G(特征1) = H(样本) - H(样本|特征1) = 0.97 - 0.552 = 0.418

> G(特征2) = H(样本) - H(样本|特征2) = 0.97 - 0.8 = 0.17