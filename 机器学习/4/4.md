# 朴素贝叶斯

白宫每天都会收到世界各地的电子邮件，但其中一些是垃圾邮件，如果不及时处理，就会影响工作效率。为此，白宫负责人希望我们团队构建一个邮件过滤系统，使得垃圾电子邮件被总统正式查阅之前，能被过滤。以下是已经分类好的邮件：

```
正常邮件：
   1 my dog has flea problems help please
   2 my dalmation is so cute I love him
   3 mr licks ate my steak how to stop him
   
垃圾邮件：
   4 maybe not take him to dog park stupid
   5 stop posting stupid worthless garbage
   6 quit buying worthless dog food stupid
````

团队将这样一个有挑战性的任务交给了小园，那下面我们看看小园是如何解决这个问题的。

## 词向量

刚接到任务，小园就遇上了麻烦：之前学习的所有算法中的表格都是有特征和目标变量的。但是现在的样本虽然有目标变量：正常邮件和垃圾邮件，但是没有特征。为此，小园绞尽脑汁，想出了一个奇招：词向量。

首先，小园对6封邮件进行分词，即将每封邮件分解成单词：

```
正常邮件：
    1 ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']
	2 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him']
	3 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him']
	
垃圾邮件：
    4 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid']
	5 ['stop', 'posting', 'stupid', 'worthless', 'garbage']
	6 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']
```
		
其次，小园统计了6份邮件中所有出现过的单词：

> cute love help garbage quit I problems is park stop flea dalmation licks food not him buying posting has worthless ate to maybe please dog how stupid so take mr steak my

最后，小园以这32个不同的单词作为特征，将每封邮件邮件转化为词向量：

```
正常邮件：
    1 [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]
	2 [1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]
	3 [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]
	
垃圾邮件：
    4 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0]
	5 [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
	6 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]
```